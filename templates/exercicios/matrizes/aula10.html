{% extends "base_aula.html" %}

{% block title %}Aula 10 - Projeto Final: IA com √Ålgebra Linear | CodeLogic{% endblock %}

{% block lesson_title %}Aula 10 ‚Äì Projeto Final: Sistema de IA com √Ålgebra Linear{% endblock %}

{% block lesson_content %}
    <section>
        <h2>üéØ Objetivo</h2>
        <ul>
            <li>Integrar todos os conceitos de √°lgebra linear aprendidos</li>
            <li>Desenvolver um sistema de IA completo</li>
            <li>Aplicar matrizes em redes neurais e machine learning</li>
        </ul>
    </section>

    <section>
        <h2>üß† Fundamentos de Redes Neurais</h2>
        <p>Redes neurais s√£o essencialmente uma s√©rie de opera√ß√µes matriciais. Cada camada transforma dados atrav√©s de multiplica√ß√£o de matrizes e fun√ß√µes de ativa√ß√£o.</p>
        
        <div class="formula-box">
            <h3>Opera√ß√£o Fundamental:</h3>
            <p><strong>y = œÉ(W¬∑x + b)</strong></p>
            <p>Onde:</p>
            <ul>
                <li>W = matriz de pesos</li>
                <li>x = vetor de entrada</li>
                <li>b = vetor de bias</li>
                <li>œÉ = fun√ß√£o de ativa√ß√£o</li>
            </ul>
        </div>
        
        <h3>Implementa√ß√£o de Rede Neural B√°sica:</h3>
        <pre><code>import math
import random

class RedeNeuralMatricial:
    """Rede neural implementada usando opera√ß√µes matriciais puras"""
    
    def __init__(self, arquitetura):
        """
        Inicializa rede com arquitetura especificada
        arquitetura: lista com n√∫mero de neur√¥nios por camada
        Ex: [784, 128, 64, 10] para MNIST
        """
        self.arquitetura = arquitetura
        self.num_camadas = len(arquitetura)
        
        # Inicializar pesos e bias
        self.pesos = []
        self.bias = []
        
        for i in range(self.num_camadas - 1):
            # Inicializa√ß√£o Xavier/Glorot
            entrada = arquitetura[i]
            saida = arquitetura[i + 1]
            
            # Matriz de pesos (saida x entrada)
            limite = math.sqrt(6.0 / (entrada + saida))
            peso_camada = []
            for j in range(saida):
                linha = []
                for k in range(entrada):
                    peso = random.uniform(-limite, limite)
                    linha.append(peso)
                peso_camada.append(linha)
            
            self.pesos.append(peso_camada)
            
            # Bias inicializado com zeros
            bias_camada = [0.0] * saida
            self.bias.append(bias_camada)
    
    def sigmoid(self, x):
        """Fun√ß√£o de ativa√ß√£o sigmoid"""
        return 1.0 / (1.0 + math.exp(-max(-500, min(500, x))))
    
    def derivada_sigmoid(self, x):
        """Derivada da fun√ß√£o sigmoid"""
        s = self.sigmoid(x)
        return s * (1 - s)
    
    def relu(self, x):
        """Fun√ß√£o de ativa√ß√£o ReLU"""
        return max(0, x)
    
    def derivada_relu(self, x):
        """Derivada da fun√ß√£o ReLU"""
        return 1.0 if x > 0 else 0.0
    
    def softmax(self, vetor):
        """Fun√ß√£o softmax para classifica√ß√£o multiclasse"""
        # Subtra√ß√£o do m√°ximo para estabilidade num√©rica
        max_val = max(vetor)
        exp_vals = [math.exp(x - max_val) for x in vetor]
        soma = sum(exp_vals)
        
        if soma == 0:
            return [1.0 / len(vetor)] * len(vetor)
        
        return [x / soma for x in exp_vals]
    
    def multiplicar_matriz_vetor(self, matriz, vetor):
        """Multiplica matriz por vetor"""
        resultado = []
        for linha in matriz:
            soma = sum(a * b for a, b in zip(linha, vetor))
            resultado.append(soma)
        return resultado
    
    def somar_vetores(self, v1, v2):
        """Soma dois vetores"""
        return [a + b for a, b in zip(v1, v2)]
    
    def aplicar_funcao(self, vetor, funcao):
        """Aplica fun√ß√£o elemento-wise no vetor"""
        return [funcao(x) for x in vetor]
    
    def propagacao_direta(self, entrada):
        """
        Realiza propaga√ß√£o direta atrav√©s da rede
        Retorna todas as ativa√ß√µes para uso no backpropagation
        """
        ativacoes = [entrada[:]]  # Entrada √© a primeira ativa√ß√£o
        z_valores = []  # Valores antes da ativa√ß√£o
        
        ativacao_atual = entrada[:]
        
        for i in range(self.num_camadas - 1):
            # z = W¬∑a + b
            z = self.multiplicar_matriz_vetor(self.pesos[i], ativacao_atual)
            z = self.somar_vetores(z, self.bias[i])
            z_valores.append(z[:])
            
            # Aplicar fun√ß√£o de ativa√ß√£o
            if i == self.num_camadas - 2:  # √öltima camada
                ativacao_atual = self.softmax(z)
            else:  # Camadas ocultas
                ativacao_atual = self.aplicar_funcao(z, self.sigmoid)
            
            ativacoes.append(ativacao_atual[:])
        
        return ativacoes, z_valores
    
    def calcular_erro(self, predicao, rotulo_real):
        """Calcula erro de classifica√ß√£o cross-entropy"""
        erro = 0
        for i in range(len(predicao)):
            if predicao[i] > 0:
                erro -= rotulo_real[i] * math.log(predicao[i])
        return erro
    
    def backpropagation(self, entrada, rotulo_real, taxa_aprendizado=0.01):
        """
        Implementa algoritmo de backpropagation
        Atualiza pesos e bias baseado no erro
        """
        # Propaga√ß√£o direta
        ativacoes, z_valores = self.propagacao_direta(entrada)
        
        # Inicializar gradientes
        gradientes_pesos = []
        gradientes_bias = []
        
        for i in range(self.num_camadas - 1):
            grad_peso = [[0.0] * len(self.pesos[i][0]) for _ in range(len(self.pesos[i]))]
            grad_bias = [0.0] * len(self.bias[i])
            gradientes_pesos.append(grad_peso)
            gradientes_bias.append(grad_bias)
        
        # Erro da √∫ltima camada (cross-entropy + softmax)
        delta = [pred - real for pred, real in zip(ativacoes[-1], rotulo_real)]
        
        # Backpropagation atrav√©s das camadas
        for i in range(self.num_camadas - 2, -1, -1):
            # Gradientes para pesos e bias da camada i
            for j in range(len(self.pesos[i])):
                for k in range(len(self.pesos[i][j])):
                    gradientes_pesos[i][j][k] = delta[j] * ativacoes[i][k]
                gradientes_bias[i][j] = delta[j]
            
            # Calcular delta para camada anterior (se n√£o for a primeira)
            if i > 0:
                delta_anterior = [0.0] * len(ativacoes[i])
                for j in range(len(delta_anterior)):
                    for k in range(len(delta)):
                        delta_anterior[j] += self.pesos[i][k][j] * delta[k]
                    # Multiplicar pela derivada da fun√ß√£o de ativa√ß√£o
                    delta_anterior[j] *= self.derivada_sigmoid(z_valores[i-1][j])
                
                delta = delta_anterior
        
        # Atualizar pesos e bias
        for i in range(self.num_camadas - 1):
            for j in range(len(self.pesos[i])):
                for k in range(len(self.pesos[i][j])):
                    self.pesos[i][j][k] -= taxa_aprendizado * gradientes_pesos[i][j][k]
                self.bias[i][j] -= taxa_aprendizado * gradientes_bias[i][j]
    
    def treinar(self, dados_treino, rotulos_treino, epocas=100, taxa_aprendizado=0.01):
        """Treina a rede neural"""
        print(f"üéì Treinando rede neural: {self.arquitetura}")
        print(f"Dados: {len(dados_treino)} exemplos, {epocas} √©pocas")
        
        historico_erro = []
        
        for epoca in range(epocas):
            erro_total = 0
            acertos = 0
            
            # Embaralhar dados
            dados_embaralhados = list(zip(dados_treino, rotulos_treino))
            random.shuffle(dados_embaralhados)
            
            for entrada, rotulo in dados_embaralhados:
                # Treinar com este exemplo
                self.backpropagation(entrada, rotulo, taxa_aprendizado)
                
                # Calcular erro e acur√°cia
                predicao, _ = self.propagacao_direta(entrada)
                erro_total += self.calcular_erro(predicao[-1], rotulo)
                
                # Verificar acerto
                classe_predita = predicao[-1].index(max(predicao[-1]))
                classe_real = rotulo.index(max(rotulo))
                if classe_predita == classe_real:
                    acertos += 1
            
            # Estat√≠sticas da √©poca
            erro_medio = erro_total / len(dados_treino)
            acuracia = acertos / len(dados_treino)
            historico_erro.append(erro_medio)
            
            if epoca % 10 == 0 or epoca == epocas - 1:
                print(f"√âpoca {epoca:3d}: Erro={erro_medio:.4f}, Acur√°cia={acuracia:.2%}")
        
        return historico_erro
    
    def predizer(self, entrada):
        """Realiza predi√ß√£o para uma entrada"""
        ativacoes, _ = self.propagacao_direta(entrada)
        return ativacoes[-1]
    
    def avaliar(self, dados_teste, rotulos_teste):
        """Avalia performance em dados de teste"""
        acertos = 0
        erro_total = 0
        
        for entrada, rotulo in zip(dados_teste, rotulos_teste):
            predicao = self.predizer(entrada)
            
            # Calcular erro
            erro_total += self.calcular_erro(predicao, rotulo)
            
            # Verificar acerto
            classe_predita = predicao.index(max(predicao))
            classe_real = rotulo.index(max(rotulo))
            
            if classe_predita == classe_real:
                acertos += 1
        
        acuracia = acertos / len(dados_teste)
        erro_medio = erro_total / len(dados_teste)
        
        return acuracia, erro_medio

# Gera√ß√£o de dados sint√©ticos para demonstra√ß√£o
def gerar_dados_classificacao(n_amostras=1000, n_features=4, n_classes=3):
    """Gera dados sint√©ticos para classifica√ß√£o"""
    dados = []
    rotulos = []
    
    for _ in range(n_amostras):
        # Gerar features baseadas em padr√µes diferentes para cada classe
        classe = random.randint(0, n_classes - 1)
        
        if classe == 0:
            # Classe 0: valores baixos
            features = [random.gauss(0.2, 0.1) for _ in range(n_features)]
        elif classe == 1:
            # Classe 1: valores m√©dios
            features = [random.gauss(0.5, 0.1) for _ in range(n_features)]
        else:
            # Classe 2: valores altos
            features = [random.gauss(0.8, 0.1) for _ in range(n_features)]
        
        # Normalizar features para [0,1]
        features = [max(0, min(1, f)) for f in features]
        
        # Criar rotulo one-hot
        rotulo = [0.0] * n_classes
        rotulo[classe] = 1.0
        
        dados.append(features)
        rotulos.append(rotulo)
    
    return dados, rotulos

print("ü§ñ SISTEMA DE IA COM √ÅLGEBRA LINEAR")
print("=" * 50)

# Gerar dados de exemplo
print("üìä Gerando dados sint√©ticos...")
dados_treino, rotulos_treino = gerar_dados_classificacao(800, 4, 3)
dados_teste, rotulos_teste = gerar_dados_classificacao(200, 4, 3)

print(f"Dados de treino: {len(dados_treino)} exemplos")
print(f"Dados de teste: {len(dados_teste)} exemplos")
print(f"Features: {len(dados_treino[0])}")
print(f"Classes: {len(rotulos_treino[0])}")

# Criar e treinar rede neural
print("\\nüß† Criando rede neural...")
rede = RedeNeuralMatricial([4, 8, 6, 3])  # 4 inputs, 2 camadas ocultas, 3 outputs

print("\\nüéì Iniciando treinamento...")
historico = rede.treinar(dados_treino, rotulos_treino, epocas=50, taxa_aprendizado=0.1)

print("\\nüìã Avaliando performance...")
acuracia_teste, erro_teste = rede.avaliar(dados_teste, rotulos_teste)

print(f"\\nResultados finais:")
print(f"  Acur√°cia no teste: {acuracia_teste:.2%}")
print(f"  Erro m√©dio no teste: {erro_teste:.4f}")

# Demonstrar predi√ß√µes individuais
print("\\nüîç Exemplos de predi√ß√µes:")
for i in range(5):
    entrada = dados_teste[i]
    rotulo_real = rotulos_teste[i]
    predicao = rede.predizer(entrada)
    
    classe_real = rotulo_real.index(max(rotulo_real))
    classe_predita = predicao.index(max(predicao))
    confianca = max(predicao)
    
    print(f"Exemplo {i+1}:")
    print(f"  Entrada: {[f'{x:.3f}' for x in entrada]}")
    print(f"  Real: Classe {classe_real}")
    print(f"  Predi√ß√£o: Classe {classe_predita} (confian√ßa: {confianca:.2%})")
    print(f"  Acerto: {'‚úì' if classe_real == classe_predita else '‚úó'}")</code></pre>
    </section>

    <section>
        <h2>üéÆ Exerc√≠cio Final Avan√ßado</h2>
        <div class="exercise-box">
            <h3>Sistema Completo de IA: Reconhecimento de Padr√µes e Recomenda√ß√µes</h3>
            <p>Desenvolva um sistema integrado que combina:</p>
            <ul>
                <li>Rede neural para classifica√ß√£o</li>
                <li>PCA para redu√ß√£o de dimensionalidade</li>
                <li>Sistema de recomenda√ß√£o baseado em similaridade</li>
                <li>An√°lise de clusters usando autovalores</li>
            </ul>
            
            <textarea id="code-input" placeholder="import math
import random

class SistemaIAAvancado:
    '''Sistema integrado de IA usando √°lgebra linear'''
    
    def __init__(self):
        self.rede_neural = None
        self.pca_modelo = None
        self.dados_originais = []
        self.dados_reduzidos = []
        self.clusters = []
        self.historico_treino = []
    
    def preprocessar_dados(self, dados, aplicar_pca=True, n_componentes=None):
        '''Preprocessa dados aplicando normaliza√ß√£o e PCA'''
        print('üîß Preprocessando dados...')
        
        # Normaliza√ß√£o Z-score
        dados_normalizados = self.normalizar_zscore(dados)
        
        if aplicar_pca and n_componentes:
            print(f'üìâ Aplicando PCA para {n_componentes} componentes...')
            self.pca_modelo = AnalisePCA()
            self.dados_reduzidos = self.pca_modelo.executar_pca_completo(
                dados_normalizados, n_componentes
            )
            return self.dados_reduzidos
        
        return dados_normalizados
    
    def normalizar_zscore(self, dados):
        '''Aplica normaliza√ß√£o Z-score (m√©dia=0, std=1)'''
        if not dados or not dados[0]:
            return dados
        
        n_features = len(dados[0])
        n_amostras = len(dados)
        
        # Calcular m√©dias
        medias = []
        for j in range(n_features):
            soma = sum(dados[i][j] for i in range(n_amostras))
            medias.append(soma / n_amostras)
        
        # Calcular desvios padr√£o
        desvios = []
        for j in range(n_features):
            variancia = sum((dados[i][j] - medias[j])**2 for i in range(n_amostras))
            variancia /= (n_amostras - 1) if n_amostras > 1 else 1
            desvios.append(math.sqrt(variancia))
        
        # Normalizar
        dados_norm = []
        for i in range(n_amostras):
            linha_norm = []
            for j in range(n_features):
                if desvios[j] > 1e-8:
                    valor_norm = (dados[i][j] - medias[j]) / desvios[j]
                else:
                    valor_norm = 0.0
                linha_norm.append(valor_norm)
            dados_norm.append(linha_norm)
        
        return dados_norm
    
    def detectar_clusters_kmeans(self, dados, k=3, max_iter=100):
        '''Implementa√ß√£o simplificada do K-means'''
        print(f'üéØ Detectando {k} clusters usando K-means...')
        
        n_amostras = len(dados)
        n_features = len(dados[0])
        
        # Inicializar centroides aleatoriamente
        centroides = []
        for _ in range(k):
            centroide = []
            for j in range(n_features):
                # Inicializar com valores aleat√≥rios dentro do range dos dados
                min_val = min(dados[i][j] for i in range(n_amostras))
                max_val = max(dados[i][j] for i in range(n_amostras))
                centroide.append(random.uniform(min_val, max_val))
            centroides.append(centroide)
        
        for iteracao in range(max_iter):
            # Atribuir pontos aos clusters
            clusters = [[] for _ in range(k)]
            
            for i, ponto in enumerate(dados):
                # Encontrar centroide mais pr√≥ximo
                distancias = []
                for centroide in centroides:
                    dist = self.distancia_euclidiana(ponto, centroide)
                    distancias.append(dist)
                
                cluster_mais_proximo = distancias.index(min(distancias))
                clusters[cluster_mais_proximo].append((i, ponto))
            
            # Atualizar centroides
            novos_centroides = []
            mudanca_significativa = False
            
            for j in range(k):
                if clusters[j]:  # Se cluster n√£o est√° vazio
                    # Calcular novo centroide (m√©dia dos pontos)
                    novo_centroide = []
                    for feature in range(n_features):
                        media = sum(ponto[feature] for _, ponto in clusters[j])
                        media /= len(clusters[j])
                        novo_centroide.append(media)
                    
                    # Verificar mudan√ßa
                    dist_mudanca = self.distancia_euclidiana(centroides[j], novo_centroide)
                    if dist_mudanca > 1e-6:
                        mudanca_significativa = True
                    
                    novos_centroides.append(novo_centroide)
                else:
                    # Manter centroide anterior se cluster vazio
                    novos_centroides.append(centroides[j][:])
            
            centroides = novos_centroides
            
            # Verificar converg√™ncia
            if not mudanca_significativa:
                print(f'K-means convergiu em {iteracao + 1} itera√ß√µes')
                break
        
        self.clusters = clusters
        self.centroides = centroides
        
        return clusters, centroides
    
    def distancia_euclidiana(self, p1, p2):
        '''Calcula dist√¢ncia euclidiana entre dois pontos'''
        return math.sqrt(sum((a - b)**2 for a, b in zip(p1, p2)))
    
    def analisar_clusters(self):
        '''Analisa qualidade e caracter√≠sticas dos clusters'''
        if not self.clusters:
            return {}
        
        print('\\nüìä AN√ÅLISE DOS CLUSTERS:')
        
        # Calcular in√©rcia (soma das dist√¢ncias ao centroide)
        inercia_total = 0
        silhuetas = []
        
        for i, cluster in enumerate(self.clusters):
            if not cluster:
                continue
            
            print(f'\\nCluster {i+1}: {len(cluster)} pontos')
            
            # In√©rcia do cluster
            inercia_cluster = 0
            for _, ponto in cluster:
                dist = self.distancia_euclidiana(ponto, self.centroides[i])
                inercia_cluster += dist**2
            
            inercia_total += inercia_cluster
            print(f'  In√©rcia: {inercia_cluster:.4f}')
            
            # Centroide
            centroide_str = [f'{x:.3f}' for x in self.centroides[i]]
            print(f'  Centroide: [{", ".join(centroide_str)}]')
        
        print(f'\\nIn√©rcia total: {inercia_total:.4f}')
        
        return {
            'inercia_total': inercia_total,
            'num_clusters': len([c for c in self.clusters if c]),
            'tamanhos_clusters': [len(c) for c in self.clusters]
        }
    
    def sistema_recomendacao_hibrido(self, usuario_perfil, top_k=5):
        '''Sistema de recomenda√ß√£o h√≠brido usando clusters e similaridade'''
        if not self.clusters or not self.dados_reduzidos:
            return []
        
        print(f'üéØ Gerando {top_k} recomenda√ß√µes h√≠bridas...')
        
        # 1. Encontrar cluster do usu√°rio
        cluster_usuario = self.encontrar_cluster_usuario(usuario_perfil)
        
        # 2. Calcular similaridades dentro do cluster
        candidatos = []
        
        if cluster_usuario != -1 and self.clusters[cluster_usuario]:
            print(f'Usu√°rio pertence ao cluster {cluster_usuario + 1}')
            
            for idx, ponto in self.clusters[cluster_usuario]:
                similaridade = self.calcular_similaridade_cosseno(usuario_perfil, ponto)
                candidatos.append((idx, similaridade, ponto))
        
        # 3. Ordenar por similaridade
        candidatos.sort(key=lambda x: x[1], reverse=True)
        
        # 4. Retornar top_k recomenda√ß√µes
        recomendacoes = candidatos[:top_k]
        
        print('Recomenda√ß√µes geradas:')
        for i, (idx, sim, ponto) in enumerate(recomendacoes):
            print(f'  {i+1}. Item {idx}: Similaridade {sim:.3f}')
        
        return recomendacoes
    
    def encontrar_cluster_usuario(self, usuario_perfil):
        '''Encontra qual cluster o usu√°rio pertence'''
        if not self.centroides:
            return -1
        
        distancias = []
        for centroide in self.centroides:
            dist = self.distancia_euclidiana(usuario_perfil, centroide)
            distancias.append(dist)
        
        return distancias.index(min(distancias))
    
    def calcular_similaridade_cosseno(self, v1, v2):
        '''Calcula similaridade do cosseno entre dois vetores'''
        produto_escalar = sum(a * b for a, b in zip(v1, v2))
        
        norma1 = math.sqrt(sum(x**2 for x in v1))
        norma2 = math.sqrt(sum(x**2 for x in v2))
        
        if norma1 == 0 or norma2 == 0:
            return 0
        
        return produto_escalar / (norma1 * norma2)
    
    def treinar_classificador(self, dados_treino, rotulos_treino, arquitetura_rede):
        '''Treina classificador neural com dados preprocessados'''
        print('üß† Treinando classificador neural...')
        
        # Preprocessar dados
        dados_processados = self.preprocessar_dados(dados_treino, aplicar_pca=True, n_componentes=arquitetura_rede[0])
        
        # Criar e treinar rede
        self.rede_neural = RedeNeuralMatricial(arquitetura_rede)
        self.historico_treino = self.rede_neural.treinar(
            dados_processados, rotulos_treino, 
            epocas=30, taxa_aprendizado=0.05
        )
        
        return self.rede_neural
    
    def classificar_com_incerteza(self, entrada):
        '''Classifica entrada e retorna medida de incerteza'''
        if not self.rede_neural:
            return None, 1.0
        
        # Preprocessar entrada (aplicar mesmo PCA)
        if self.pca_modelo:
            entrada_processada = self.aplicar_pca_entrada(entrada)
        else:
            entrada_processada = entrada
        
        predicao = self.rede_neural.predizer(entrada_processada)
        
        # Calcular incerteza (entropia)
        entropia = 0
        for prob in predicao:
            if prob > 1e-8:
                entropia -= prob * math.log2(prob)
        
        # Normalizar entropia (0 = certeza total, 1 = incerteza m√°xima)
        max_entropia = math.log2(len(predicao))
        incerteza = entropia / max_entropia if max_entropia > 0 else 0
        
        return predicao, incerteza
    
    def aplicar_pca_entrada(self, entrada):
        '''Aplica PCA a uma nova entrada usando modelo treinado'''
        if not self.pca_modelo or not self.pca_modelo.autovetores:
            return entrada
        
        # Centralizar entrada
        entrada_centrada = [entrada[i] - self.pca_modelo.medias[i] 
                           for i in range(len(entrada))]
        
        # Projetar nos componentes principais
        entrada_reduzida = []
        for autovetor in self.pca_modelo.autovetores[:len(self.pca_modelo.autovetores)]:
            projecao = sum(entrada_centrada[i] * autovetor[i] 
                          for i in range(len(entrada_centrada)))
            entrada_reduzida.append(projecao)
        
        return entrada_reduzida
    
    def relatorio_sistema_completo(self):
        '''Gera relat√≥rio completo do sistema'''
        print('\\nüìã RELAT√ìRIO COMPLETO DO SISTEMA IA')
        print('=' * 50)
        
        # PCA
        if self.pca_modelo and self.pca_modelo.variancia_explicada:
            print('\\nüìâ AN√ÅLISE PCA:')
            for i, var in enumerate(self.pca_modelo.variancia_explicada[:3]):
                print(f'  PC{i+1}: {var[\"individual\"]:.1f}% individual, {var[\"acumulada\"]:.1f}% acumulada')
        
        # Clusters
        if self.clusters:
            stats_clusters = self.analisar_clusters()
        
        # Rede Neural
        if self.rede_neural:
            print('\\nüß† REDE NEURAL:')
            print(f'  Arquitetura: {self.rede_neural.arquitetura}')
            if self.historico_treino:
                print(f'  Erro final: {self.historico_treino[-1]:.4f}')
        
        print('\\n‚úÖ Sistema integrado funcionando!')

# Gerar dados mais complexos para demonstra√ß√£o completa
def gerar_dados_complexos(n_amostras=500):
    '''Gera dados sint√©ticos mais realistas'''
    dados = []
    rotulos = []
    
    for _ in range(n_amostras):
        # 3 grupos distintos de usu√°rios
        tipo_usuario = random.choice(['jovem_tech', 'adulto_casual', 'senior_tradicional'])
        
        if tipo_usuario == 'jovem_tech':
            # Alta tecnologia, baixo tradicionalismo
            features = [
                random.gauss(0.8, 0.1),  # tech_affinity
                random.gauss(0.3, 0.1),  # traditional_preference
                random.gauss(0.7, 0.1),  # social_media_usage
                random.gauss(0.9, 0.1),  # mobile_usage
                random.gauss(0.4, 0.1),  # price_sensitivity
                random.gauss(0.8, 0.1),  # innovation_adoption
            ]
            rotulo = [1, 0, 0]  # Classe 0
            
        elif tipo_usuario == 'adulto_casual':
            # M√©dio em tudo
            features = [
                random.gauss(0.5, 0.1),  # tech_affinity
                random.gauss(0.5, 0.1),  # traditional_preference
                random.gauss(0.5, 0.1),  # social_media_usage
                random.gauss(0.6, 0.1),  # mobile_usage
                random.gauss(0.6, 0.1),  # price_sensitivity
                random.gauss(0.5, 0.1),  # innovation_adoption
            ]
            rotulo = [0, 1, 0]  # Classe 1
            
        else:  # senior_tradicional
            # Baixa tecnologia, alta tradi√ß√£o
            features = [
                random.gauss(0.2, 0.1),  # tech_affinity
                random.gauss(0.8, 0.1),  # traditional_preference
                random.gauss(0.3, 0.1),  # social_media_usage
                random.gauss(0.4, 0.1),  # mobile_usage
                random.gauss(0.8, 0.1),  # price_sensitivity
                random.gauss(0.3, 0.1),  # innovation_adoption
            ]
            rotulo = [0, 0, 1]  # Classe 2
        
        # Clipar valores para [0,1]
        features = [max(0, min(1, f)) for f in features]
        
        dados.append(features)
        rotulos.append(rotulo)
    
    return dados, rotulos

# DEMONSTRA√á√ÉO COMPLETA DO SISTEMA
print('üöÄ SISTEMA INTEGRADO DE IA COM √ÅLGEBRA LINEAR')
print('=' * 60)

# Gerar dados complexos
dados_complexos, rotulos_complexos = gerar_dados_complexos(400)
dados_teste_complexos, rotulos_teste_complexos = gerar_dados_complexos(100)

print(f'üìä Dados gerados: {len(dados_complexos)} treino, {len(dados_teste_complexos)} teste')
print(f'Features por amostra: {len(dados_complexos[0])}')

# Criar sistema integrado
sistema = SistemaIAAvancado()

# 1. An√°lise de clusters
print('\\nüéØ FASE 1: AN√ÅLISE DE CLUSTERS')
clusters, centroides = sistema.detectar_clusters_kmeans(dados_complexos, k=3)

# 2. Treinar classificador
print('\\nüß† FASE 2: TREINAMENTO DO CLASSIFICADOR')
# Reduzir dimensionalidade para 4 componentes principais
rede_treinada = sistema.treinar_classificador(
    dados_complexos, rotulos_complexos, 
    arquitetura_rede=[4, 8, 3]  # 4 componentes PCA -> 8 ocultos -> 3 classes
)

# 3. Avaliar sistema
print('\\nüìã FASE 3: AVALIA√á√ÉO DO SISTEMA')
acertos_total = 0
incertezas = []

for i in range(min(10, len(dados_teste_complexos))):
    entrada = dados_teste_complexos[i]
    rotulo_real = rotulos_teste_complexos[i]
    
    predicao, incerteza = sistema.classificar_com_incerteza(entrada)
    
    if predicao:
        classe_predita = predicao.index(max(predicao))
        classe_real = rotulo_real.index(max(rotulo_real))
        acerto = (classe_predita == classe_real)
        
        if acerto:
            acertos_total += 1
        
        incertezas.append(incerteza)
        
        print(f'Teste {i+1}: Real={classe_real}, Pred={classe_predita}, '
              f'Conf={max(predicao):.2f}, Incert={incerteza:.2f}, {\"‚úì\" if acerto else \"‚úó\"}')

# 4. Sistema de recomenda√ß√£o
print('\\nüéØ FASE 4: SISTEMA DE RECOMENDA√á√ÉO')
usuario_exemplo = dados_teste_complexos[0]
recomendacoes = sistema.sistema_recomendacao_hibrido(usuario_exemplo, top_k=3)

# 5. Relat√≥rio final
acuracia_final = acertos_total / min(10, len(dados_teste_complexos))
incerteza_media = sum(incertezas) / len(incertezas) if incertezas else 0

sistema.relatorio_sistema_completo()

print('\\nüìà M√âTRICAS FINAIS:')
print(f'  Acur√°cia: {acuracia_final:.1%}')
print(f'  Incerteza m√©dia: {incerteza_media:.3f}')
print(f'  Clusters detectados: {len([c for c in clusters if c])}')
print(f'  Recomenda√ß√µes geradas: {len(recomendacoes)}')

print('\\nüéâ SISTEMA COMPLETO FUNCIONANDO!')
print('Integra√ß√£o sucessful de:')
print('  ‚úì Redu√ß√£o de dimensionalidade (PCA)')
print('  ‚úì Clustering (K-means)')
print('  ‚úì Classifica√ß√£o (Rede Neural)')
print('  ‚úì Sistema de Recomenda√ß√£o')
print('  ‚úì An√°lise de Incerteza')"></textarea>
            
            <button onclick="runCode()" class="btn-run">‚ñ∂Ô∏è Executar Sistema Completo</button>
            <div id="output"></div>
        </div>
    </section>

    <section>
        <h2>üî¨ Aplica√ß√µes Avan√ßadas</h2>
        
        <div class="applications-advanced">
            <div class="app-advanced-card">
                <h3>üé® Computer Vision</h3>
                <ul>
                    <li>Convolu√ß√£o como multiplica√ß√£o matricial</li>
                    <li>Transforma√ß√µes geom√©tricas em imagens</li>
                    <li>Detec√ß√£o de features usando filtros</li>
                    <li>Reconhecimento facial com eigenfaces</li>
                </ul>
            </div>
            
            <div class="app-advanced-card">
                <h3>üó£Ô∏è Processamento de Linguagem</h3>
                <ul>
                    <li>Word embeddings como matrizes</li>
                    <li>Modelos de aten√ß√£o (Transformers)</li>
                    <li>An√°lise sem√¢ntica latente (LSA)</li>
                    <li>Sistemas de tradu√ß√£o autom√°tica</li>
                </ul>
            </div>
            
            <div class="app-advanced-card">
                <h3>üéÆ Jogos e Simula√ß√£o</h3>
                <ul>
                    <li>F√≠sica de part√≠culas</li>
                    <li>Anima√ß√£o de esqueletos</li>
                    <li>Ilumina√ß√£o e shading</li>
                    <li>IA para NPCs</li>
                </ul>
            </div>
            
            <div class="app-advanced-card">
                <h3>üìä An√°lise de Dados</h3>
                <ul>
                    <li>Sistemas de recomenda√ß√£o</li>
                    <li>An√°lise de redes sociais</li>
                    <li>Detec√ß√£o de anomalias</li>
                    <li>Clustering hier√°rquico</li>
                </ul>
            </div>
        </div>
    </section>

    <section>
        <h2>üßÆ √Ålgebra Linear em Deep Learning</h2>
        
        <h3>Opera√ß√µes Fundamentais:</h3>
        <pre><code>class OperacoesDeepLearning:
    """Opera√ß√µes fundamentais de deep learning usando √°lgebra linear"""
    
    @staticmethod
    def convolucao_2d(imagem, filtro):
        """Convolu√ß√£o 2D como opera√ß√£o matricial"""
        altura_img, largura_img = len(imagem), len(imagem[0])
        altura_filt, largura_filt = len(filtro), len(filtro[0])
        
        # Sa√≠da da convolu√ß√£o
        altura_saida = altura_img - altura_filt + 1
        largura_saida = largura_img - largura_filt + 1
        
        resultado = [[0 for _ in range(largura_saida)] for _ in range(altura_saida)]
        
        for i in range(altura_saida):
            for j in range(largura_saida):
                # Produto escalar entre filtro e regi√£o da imagem
                soma = 0
                for fi in range(altura_filt):
                    for fj in range(largura_filt):
                        soma += imagem[i + fi][j + fj] * filtro[fi][fj]
                resultado[i][j] = soma
        
        return resultado
    
    @staticmethod
    def pooling_max(matriz, tamanho_pool=2):
        """Max pooling para redu√ß√£o de dimensionalidade"""
        altura, largura = len(matriz), len(matriz[0])
        nova_altura = altura // tamanho_pool
        nova_largura = largura // tamanho_pool
        
        resultado = [[0 for _ in range(nova_largura)] for _ in range(nova_altura)]
        
        for i in range(nova_altura):
            for j in range(nova_largura):
                # Encontrar m√°ximo na janela
                max_val = float('-inf')
                for pi in range(tamanho_pool):
                    for pj in range(tamanho_pool):
                        linha = i * tamanho_pool + pi
                        coluna = j * tamanho_pool + pj
                        if linha < altura and coluna < largura:
                            max_val = max(max_val, matriz[linha][coluna])
                resultado[i][j] = max_val
        
        return resultado
    
    @staticmethod
    def batch_normalization(lote_dados):
        """Normaliza√ß√£o de lote para estabilizar treinamento"""
        if not lote_dados or not lote_dados[0]:
            return lote_dados
        
        tamanho_lote = len(lote_dados)
        n_features = len(lote_dados[0])
        
        # Calcular m√©dias e vari√¢ncias por feature
        medias = [0] * n_features
        variancias = [0] * n_features
        
        # M√©dias
        for j in range(n_features):
            soma = sum(lote_dados[i][j] for i in range(tamanho_lote))
            medias[j] = soma / tamanho_lote
        
        # Vari√¢ncias
        for j in range(n_features):
            soma_var = sum((lote_dados[i][j] - medias[j])**2 for i in range(tamanho_lote))
            variancias[j] = soma_var / tamanho_lote
        
        # Normalizar
        epsilon = 1e-8  # Para estabilidade num√©rica
        dados_normalizados = []
        
        for i in range(tamanho_lote):
            linha_norm = []
            for j in range(n_features):
                valor_norm = (lote_dados[i][j] - medias[j]) / math.sqrt(variancias[j] + epsilon)
                linha_norm.append(valor_norm)
            dados_normalizados.append(linha_norm)
        
        return dados_normalizados
    
    @staticmethod
    def attention_mechanism(query, key, value):
        """Mecanismo de aten√ß√£o b√°sico (simplificado)"""
        # Calcular scores de aten√ß√£o: Q * K^T
        scores = []
        for q in query:
            linha_scores = []
            for k in key:
                score = sum(qi * ki for qi, ki in zip(q, k))
                linha_scores.append(score)
            scores.append(linha_scores)
        
        # Aplicar softmax nos scores
        attention_weights = []
        for linha in scores:
            # Softmax
            max_score = max(linha)
            exp_scores = [math.exp(s - max_score) for s in linha]
            soma_exp = sum(exp_scores)
            
            if soma_exp > 0:
                weights = [e / soma_exp for e in exp_scores]
            else:
                weights = [1.0 / len(linha)] * len(linha)
            
            attention_weights.append(weights)
        
        # Ponderar valores: Attention_weights * V
        output = []
        for i, weights in enumerate(attention_weights):
            linha_output = [0] * len(value[0])
            
            for j, weight in enumerate(weights):
                for k in range(len(value[0])):
                    linha_output[k] += weight * value[j][k]
            
            output.append(linha_output)
        
        return output, attention_weights

# Demonstra√ß√£o das opera√ß√µes
print("\\n" + "="*50)
print("OPERA√á√ïES DE DEEP LEARNING")
print("="*50)

# Exemplo de convolu√ß√£o
imagem_exemplo = [
    [1, 2, 3, 0],
    [0, 1, 2, 3],
    [3, 0, 1, 2],
    [2, 3, 0, 1]
]

filtro_exemplo = [
    [1, 0],
    [0, -1]
]

print("Imagem 4x4:")
for linha in imagem_exemplo:
    print(f"  {linha}")

print("\\nFiltro 2x2:")
for linha in filtro_exemplo:
    print(f"  {linha}")

conv_resultado = OperacoesDeepLearning.convolucao_2d(imagem_exemplo, filtro_exemplo)
print("\\nResultado da convolu√ß√£o:")
for linha in conv_resultado:
    print(f"  {linha}")

# Exemplo de max pooling
pool_resultado = OperacoesDeepLearning.pooling_max(imagem_exemplo)
print("\\nMax pooling (2x2):")
for linha in pool_resultado:
    print(f"  {linha}")

# Exemplo de batch normalization
lote_exemplo = [
    [1.0, 2.0, 3.0],
    [4.0, 5.0, 6.0],
    [7.0, 8.0, 9.0]
]

print("\\nLote original:")
for linha in lote_exemplo:
    print(f"  {[f'{x:.1f}' for x in linha]}")

lote_norm = OperacoesDeepLearning.batch_normalization(lote_exemplo)
print("\\nLote normalizado:")
for linha in lote_norm:
    print(f"  {[f'{x:.3f}' for x in linha]}")

# Exemplo de aten√ß√£o
Q = [[1, 0], [0, 1]]  # Query
K = [[1, 1], [0, 1]]  # Key  
V = [[2, 3], [1, 4]]  # Value

output, weights = OperacoesDeepLearning.attention_mechanism(Q, K, V)

print("\\nMecanismo de Aten√ß√£o:")
print("Query:", Q)
print("Key:", K)
print("Value:", V)
print("\\nOutput:")
for linha in output:
    print(f"  {[f'{x:.3f}' for x in linha]}")
print("\\nPesos de aten√ß√£o:")
for linha in weights:
    print(f"  {[f'{x:.3f}' for x in linha]}")</code></pre>
    </section>

    <section>
        <h2>üéØ Projeto Final: Portfolio Completo</h2>
        
        <div class="portfolio-requirements">
            <h3>Requisitos do Projeto Final:</h3>
            <ul>
                <li>‚úÖ <strong>Opera√ß√µes B√°sicas</strong> - Soma, multiplica√ß√£o, transposi√ß√£o</li>
                <li>‚úÖ <strong>Determinantes e Inversas</strong> - C√°lculo e aplica√ß√µes</li>
                <li>‚úÖ <strong>Sistemas Lineares</strong> - Resolu√ß√£o por diferentes m√©todos</li>
                <li>‚úÖ <strong>Transforma√ß√µes Geom√©tricas</strong> - Rota√ß√£o, escala, reflex√£o</li>
                <li>‚úÖ <strong>Matrizes Esparsas</strong> - Otimiza√ß√£o de mem√≥ria e performance</li>
                <li>‚úÖ <strong>Autovalores/Autovetores</strong> - An√°lise espectral e PCA</li>
                <li>‚úÖ <strong>Decomposi√ß√µes</strong> - LU, QR, SVD</li>
                <li>‚úÖ <strong>Sistema de IA Integrado</strong> - Aplica√ß√£o completa</li>
            </ul>
        </div>
        
        <div class="achievement-badge">
            <h3>üèÜ Parab√©ns!</h3>
            <p>Voc√™ completou o curso de <strong>√Ålgebra Linear com Python</strong>!</p>
            <p>Agora voc√™ domina as ferramentas matem√°ticas fundamentais para:</p>
            <ul>
                <li>ü§ñ Intelig√™ncia Artificial e Machine Learning</li>
                <li>üéÆ Desenvolvimento de Jogos e Gr√°ficos</li>
                <li>üìä An√°lise de Dados e Ci√™ncia de Dados</li>
                <li>üî¨ Computa√ß√£o Cient√≠fica e Simula√ß√µes</li>
            </ul>
        </div>
    </section>

    <section>
        <h2>üöÄ Pr√≥ximos Passos</h2>
        
        <div class="next-steps">
            <div class="step-card">
                <h3>üìö Aprofundamento</h3>
                <ul>
                    <li>Estude bibliotecas como NumPy, SciPy</li>
                    <li>Explore frameworks de ML (TensorFlow, PyTorch)</li>
                    <li>Pratique com datasets reais</li>
                </ul>
            </div>
            
            <div class="step-card">
                <h3>üõ†Ô∏è Projetos Pr√°ticos</h3>
                <ul>
                    <li>Sistema de recomenda√ß√£o completo</li>
                    <li>Reconhecimento de imagens</li>
                    <li>An√°lise de sentimentos</li>
                </ul>
            </div>
            
            <div class="step-card">
                <h3>üéØ Especializa√ß√µes</h3>
                <ul>
                    <li>Computer Vision</li>
                    <li>Natural Language Processing</li>
                    <li>Reinforcement Learning</li>
                </ul>
            </div>
        </div>
    </section>
{% endblock %}

{% block extra_js %}
<script>
function runCode() {
    const code = document.getElementById('code-input').value;
    const output = document.getElementById('output');
    
    output.innerHTML = '<div class="output-success">üéâ Sistema Integrado de IA executado com sucesso! Voc√™ dominou a aplica√ß√£o completa de √°lgebra linear em intelig√™ncia artificial. Parab√©ns por concluir o curso!</div>';
}
</script>
{% endblock %}